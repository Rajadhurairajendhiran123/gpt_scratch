1. Learned to build GPT-2 architecture from scratch, understanding each component like tokenization, attention, and transformer blocks.  
2. Gained hands-on experience in training language models using PyTorch and managing datasets efficiently.  
3. Explored key NLP concepts like positional encoding, causal masking, and text generation techniques.  
4. Developed debugging and optimization skills critical for real-world AI model deployment.  
5. This experience strengthens my profile for Generative AI, NLP engineering, and research-based AI product development roles.

